# -*- coding: utf-8 -*-
"""hondong_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1teTRBbMMZnxcY4XiYrTlM5Fh8-Af32Vk
"""

import gdown
gdown.download('https://bit.ly/3eecMKZ',
'남산도서관 장서 대출목록 (2021년 04월).csv', quiet=False)

# with open('남산도서관 장서 대출목록 (2021년 04월).csv') as f:
#   print(f.readline())

import chardet
with open('남산도서관 장서 대출목록 (2021년 04월).csv', mode='rb') as f:
  d= f.readline()

print(chardet.detect(d))

with open('남산도서관 장서 대출목록 (2021년 04월).csv', encoding='euc-kr') as f:
  print(f.readline())
  print(f.readline())

import pandas as pd

df = pd.read_csv('남산도서관 장서 대출목록 (2021년 04월).csv', encoding='euc-kr', low_memory=False, dtype={'ISBN': str,
'세트 ISBN': str,
'주제분류번호': str}) ##데이터를 한번에 읽게해주는 속성 lowmemory dtype은 데이터의 속성을 미리지정해서 데이터의 크기를줄인다.

df.head()

df.to_csv("ns_202104.csv", index=False)

with open("ns_202104.csv") as f:
  for i in range(3) :
    print(f.readline(), end='')

ns_df = pd.read_csv('ns_202104.csv',index_col=0, low_memory=False)

ns_df.head()

d = {"name":"혼자 공부하는 데이터 분석"}
print(d['name'])
type(d)

import json

d_str = json.dumps(d, ensure_ascii=False)##한글을 그대로 출력하기 위해
print(d_str)

print(type(d_str))

d2 = json.loads(d_str)
print(d2['name'])

print(type(d2))

d3 = json.loads('{"name": "혼자 공부하는 데이터 분석", "author": "박해선", "year": 2022}')
print(d3['name'])
print(d3['author'])
print(d3['year'])

d3 = json.loads('{"name": "혼자 공부하는 데이터 분석", "author": ["박해선","홍길동"], "year": 2022}')

print(d3['author'][1])

d4_str= """[
  {"name": "혼자 공부하는 데이터 분석", "author": "박해선", "year": 2023},
  {"name": "혼자 공부하는 데이터 마이닝", "author": "박인선", "year": 2022}
]"""

d4= json.loads(d4_str)
print(d4[0]['name'])
print(type(d4))

pd.read_json(d4_str)

pd.DataFrame(d4)

x_str = """
<book>
  <name>혼자 공부하는 데이터분석</name>
  <author>박해선</author>
  <year>2022</year>
</book>
"""

import xml.etree.ElementTree as et

book = et.fromstring(x_str)

print(type(book))

print(book.tag)

book_childs = list(book)
print(book_childs)

name, author, year = book_childs

print(name.text)
print(author.text)

name = book.findtext('name')
author = book.findtext('author')
year = book.findtext('year')
print(name)
print(author)

url = "http://data4library.kr/api/loanItemSrch?format=json&startDt=2021-04-01&endDt= 2021-04-30&age=20&authKey=	969ec00220e4665ade4ffdb3e8cf27fb6e84256de9c46298490de86e8cdb98a0"

import requests

r = requests.get(url)

data = r.json()
print(data)

data

books = []
for i in data['response']['docs']:
  books.append(i['doc'])
  books = [d['doc'] for d in
data['response']['docs']]

books

books_df = pd.DataFrame(books)
books_df

books_df.to_json("20s_best_book.json")

##웹스크래핑

import gdown

gdown.download('https://bit.ly/3q9SZix', '20s_best_book.json', quiet=False)

books_df = pd.read_json("20s_best_book.json")
books_df.head()

books = books_df[['no', 'ranking', 'bookname', 'authors','publisher', 'publication_year', 'isbn13']]

books_df.loc[[0,1], ['bookname', 'authors']]

books = books_df.loc[:, 'no':'isbn13']

isbn = 9791190090018
url = 'http://www.yes24.com/Product/Search?domain=BOOK&query={}'

r= requests.get(url.format(isbn))

print(r.text)

from bs4 import BeautifulSoup

soup = BeautifulSoup(r.text, 'html.parser')

prd_link = soup.find('a', attrs={'class':'gd_name'})

print(prd_link)

print(prd_link['href'])

url = 'http://www.yes24.com'+prd_link['href']
r = requests.get(url)

print(r.text)



soup = BeautifulSoup(r.text, 'html.parser')

prd_detail = soup.find('div', attrs={'id':'infoset_specific'})
print(prd_detail)

prd_tr_list = prd_detail.find_all('tr')
print(prd_tr_list)

for tr in prd_tr_list:
  if tr.find('th').get_text() == "쪽수, 무게, 크기":
    page_td = tr.find('td').get_text()
    break

print(page_td)

print(page_td.)